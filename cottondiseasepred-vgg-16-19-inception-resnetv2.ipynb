{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-04T18:45:19.595318Z","iopub.execute_input":"2022-04-04T18:45:19.595850Z","iopub.status.idle":"2022-04-04T18:45:19.622466Z","shell.execute_reply.started":"2022-04-04T18:45:19.595754Z","shell.execute_reply":"2022-04-04T18:45:19.621829Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"**LOADING FILES**","metadata":{}},{"cell_type":"code","source":"import os\n\ntrain_set = '../input/cotton-disease-dataset/Cotton Disease/train'\ntest_set = '../input/cotton-disease-dataset/Cotton Disease/test'\nval_set = '../input/cotton-disease-dataset/Cotton Disease/val'","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:45:19.857676Z","iopub.execute_input":"2022-04-04T18:45:19.857909Z","iopub.status.idle":"2022-04-04T18:45:19.861650Z","shell.execute_reply.started":"2022-04-04T18:45:19.857882Z","shell.execute_reply":"2022-04-04T18:45:19.860975Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**TRAIN FILES**","metadata":{}},{"cell_type":"code","source":"train_dirs = os.listdir(train_set)\nprint(train_dirs)\n\ntrain_df = []\n\nfor dirs in train_dirs:\n    path = '../input/cotton-disease-dataset/Cotton Disease/train/' + dirs\n    files = os.listdir(path)\n    train_df.extend([[dirs, len(files)]])\n    print(dirs, len(files))\n\nprint(train_df)\ntrain_df = pd.DataFrame(train_df, columns=['file', 'length'])\ntrain_df\n\ntotal_train_files = train_df.length.sum()\nprint('Total train files', total_train_files)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:45:20.141609Z","iopub.execute_input":"2022-04-04T18:45:20.142088Z","iopub.status.idle":"2022-04-04T18:45:20.737448Z","shell.execute_reply.started":"2022-04-04T18:45:20.142031Z","shell.execute_reply":"2022-04-04T18:45:20.736666Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"**TEST FILES**","metadata":{}},{"cell_type":"code","source":"test_dirs = os.listdir(test_set)\nprint(test_dirs)\n\ntest_df = []\n\nfor dirs in test_dirs:\n    path = '../input/cotton-disease-dataset/Cotton Disease/test/' + dirs\n    files = os.listdir(path)\n    test_df.extend([[dirs, len(files)]])\n    print(dirs, len(files))\n\nprint(test_df)\ntest_df = pd.DataFrame(test_df, columns=['file', 'length'])\ntest_df\n\ntotal_test_files = test_df.length.sum()\nprint('Total test files', total_test_files)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:45:20.739380Z","iopub.execute_input":"2022-04-04T18:45:20.740118Z","iopub.status.idle":"2022-04-04T18:45:20.788444Z","shell.execute_reply.started":"2022-04-04T18:45:20.740078Z","shell.execute_reply":"2022-04-04T18:45:20.787737Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"**VALIDATION FILES**","metadata":{}},{"cell_type":"code","source":"val_dirs = os.listdir(val_set)\nprint(val_dirs)\n\nval_dirs = os.listdir(val_set)\nprint(val_dirs)\n\nval_df = []\n\nfor dirs in val_dirs:\n    path = '../input/cotton-disease-dataset/Cotton Disease/val/' + dirs\n    files = os.listdir(path)\n    val_df.extend([[dirs, len(files)]])\n    print(dirs, len(files))\n\nval_df = pd.DataFrame(val_df, columns=['file', 'length'])\nval_df\n\ntotal_val_files = val_df.length.sum()\nprint('Total val files', total_val_files)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:45:20.790474Z","iopub.execute_input":"2022-04-04T18:45:20.790851Z","iopub.status.idle":"2022-04-04T18:45:20.882955Z","shell.execute_reply.started":"2022-04-04T18:45:20.790815Z","shell.execute_reply":"2022-04-04T18:45:20.882165Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"**IMPORTING LIBRARIES**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:45:20.884769Z","iopub.execute_input":"2022-04-04T18:45:20.885316Z","iopub.status.idle":"2022-04-04T18:45:25.517416Z","shell.execute_reply.started":"2022-04-04T18:45:20.885281Z","shell.execute_reply":"2022-04-04T18:45:25.516590Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.applications.vgg19 import VGG19, preprocess_input\nfrom keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, Input, Lambda\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, image_dataset_from_directory\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom glob import glob","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:45:25.518689Z","iopub.execute_input":"2022-04-04T18:45:25.518929Z","iopub.status.idle":"2022-04-04T18:45:26.074438Z","shell.execute_reply.started":"2022-04-04T18:45:25.518899Z","shell.execute_reply":"2022-04-04T18:45:26.073716Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### **WORKING WITH FOLDERS OF TRAIN, TEST AND VAL AND COMBINING RESPECTIVE DIRECTORIES FILES**","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\ntrain_set = image_dataset_from_directory(\n    '../input/cotton-disease-dataset/Cotton Disease/train',\n    seed=45,\n    image_size = (224, 224),\n    batch_size = 32,\n)\n\nval_set = image_dataset_from_directory(\n    '../input/cotton-disease-dataset/Cotton Disease/val',\n    seed=45,\n    image_size = (224, 224),\n    batch_size = 32\n)\n\ntest_set = image_dataset_from_directory(\n    '../input/cotton-disease-dataset/Cotton Disease/test',\n    seed=45,\n    image_size = (224, 224),\n    batch_size = 32\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:45:26.076659Z","iopub.execute_input":"2022-04-04T18:45:26.077251Z","iopub.status.idle":"2022-04-04T18:45:28.755474Z","shell.execute_reply.started":"2022-04-04T18:45:26.077205Z","shell.execute_reply":"2022-04-04T18:45:28.754835Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(len(np.concatenate([i for x, i in train_set], axis=0)))\nprint(len(np.concatenate([i for x, i in test_set], axis=0)))\nprint(len(np.concatenate([i for x, i in val_set], axis=0)))","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:45:28.756929Z","iopub.execute_input":"2022-04-04T18:45:28.757365Z","iopub.status.idle":"2022-04-04T18:45:39.457583Z","shell.execute_reply.started":"2022-04-04T18:45:28.757324Z","shell.execute_reply":"2022-04-04T18:45:39.456090Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Analysing Data","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_set.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i+1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(int(labels[i]))\n        plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:45:39.458999Z","iopub.execute_input":"2022-04-04T18:45:39.459266Z","iopub.status.idle":"2022-04-04T18:45:41.240095Z","shell.execute_reply.started":"2022-04-04T18:45:39.459231Z","shell.execute_reply":"2022-04-04T18:45:41.239344Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### **Trying data augmentation but not applying on the problem**","metadata":{}},{"cell_type":"code","source":"data_augmentation = Sequential([\n    tf.keras.layers.RandomFlip('horizontal'),\n    tf.keras.layers.RandomRotation(0.1)\n])","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:45:41.241166Z","iopub.execute_input":"2022-04-04T18:45:41.241412Z","iopub.status.idle":"2022-04-04T18:45:41.578437Z","shell.execute_reply.started":"2022-04-04T18:45:41.241379Z","shell.execute_reply":"2022-04-04T18:45:41.577719Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor images, labels in train_set.take(1):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        ax = plt.subplot(3, 3, i+1)\n        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n        plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:45:41.579530Z","iopub.execute_input":"2022-04-04T18:45:41.579794Z","iopub.status.idle":"2022-04-04T18:45:43.279509Z","shell.execute_reply.started":"2022-04-04T18:45:41.579759Z","shell.execute_reply":"2022-04-04T18:45:43.278888Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"inputs = Input(shape=(224, 224))\nx = data_augmentation(inputs)\nx = tf.keras.layers.Rescaling(1./255)(x)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:45:43.282283Z","iopub.execute_input":"2022-04-04T18:45:43.282727Z","iopub.status.idle":"2022-04-04T18:45:43.374461Z","shell.execute_reply.started":"2022-04-04T18:45:43.282692Z","shell.execute_reply":"2022-04-04T18:45:43.373842Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# **Xception Net from Scratch**","metadata":{}},{"cell_type":"code","source":"def make_model(input_shape, num_classes):\n    inputs = Input(shape=input_shape)\n    # Image augmentation block\n    x = data_augmentation(inputs)\n\n    # Entry block\n    x = tf.keras.layers.Rescaling(1.0 / 255)(x)\n    x = tf.keras.layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Activation(\"relu\")(x)\n\n    x = tf.keras.layers.Conv2D(64, 3, padding=\"same\")(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Activation(\"relu\")(x)\n\n    previous_block_activation = x  # Set aside residual\n\n    for size in [128, 256, 512, 728]:\n        x = tf.keras.layers.Activation(\"relu\")(x)\n        x = tf.keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n\n        x = tf.keras.layers.Activation(\"relu\")(x)\n        x = tf.keras.layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n\n        x = tf.keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n\n        # Project residual\n        residual = tf.keras.layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n            previous_block_activation\n        )\n        x = tf.keras.layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    x = tf.keras.layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Activation(\"relu\")(x)\n\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    if num_classes == 2:\n        activation = \"sigmoid\"\n        units = 1\n    else:\n        activation = \"softmax\"\n        units = num_classes\n\n    x = tf.keras.layers.Dropout(0.5)(x)\n    outputs = tf.keras.layers.Dense(units, activation=activation)(x)\n    return Model(inputs, outputs)\n\n\nmodel = make_model(input_shape=(224, 224) + (3,), num_classes=2)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:26:27.513655Z","iopub.execute_input":"2022-04-04T19:26:27.513846Z","iopub.status.idle":"2022-04-04T19:26:27.839923Z","shell.execute_reply.started":"2022-04-04T19:26:27.513822Z","shell.execute_reply":"2022-04-04T19:26:27.839259Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"epochs = 10\n\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n]\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-3),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"],\n)\nmodel.fit(\n    train_set, epochs=epochs, callbacks=callbacks, validation_data=val_set,\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:45:45.010583Z","iopub.execute_input":"2022-04-04T18:45:45.011027Z","iopub.status.idle":"2022-04-04T18:49:27.157835Z","shell.execute_reply.started":"2022-04-04T18:45:45.010988Z","shell.execute_reply":"2022-04-04T18:49:27.156963Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(test_set)\npreds = np.argmax(preds, axis=1)\nprint(preds)\n\nmodel.evaluate(test_set)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:49:27.159036Z","iopub.execute_input":"2022-04-04T18:49:27.159308Z","iopub.status.idle":"2022-04-04T18:49:30.414589Z","shell.execute_reply.started":"2022-04-04T18:49:27.159272Z","shell.execute_reply":"2022-04-04T18:49:30.413889Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### **With so low accuracy of 26% on test set, lets try with Data Augmentation**","metadata":{}},{"cell_type":"markdown","source":"# **Data Augmentation and train/test/val set preparation**\nUsing - \n- tf.keras.preprocessing.image.ImageDataGenerator\n- tf.keras.preprocessing.image.image_dataset_from_directory\n- flow_from_directory","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    rotation_range=30,\n    fill_mode='nearest'    \n)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:49:30.416030Z","iopub.execute_input":"2022-04-04T18:49:30.416289Z","iopub.status.idle":"2022-04-04T18:49:30.421305Z","shell.execute_reply.started":"2022-04-04T18:49:30.416254Z","shell.execute_reply":"2022-04-04T18:49:30.420589Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_set = train_datagen.flow_from_directory(\n    directory='../input/cotton-disease-dataset/Cotton Disease/train',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=43\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:49:30.422914Z","iopub.execute_input":"2022-04-04T18:49:30.423591Z","iopub.status.idle":"2022-04-04T18:49:30.539132Z","shell.execute_reply.started":"2022-04-04T18:49:30.423554Z","shell.execute_reply":"2022-04-04T18:49:30.538432Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"test_set = train_datagen.flow_from_directory(\n    directory='../input/cotton-disease-dataset/Cotton Disease/test',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    seed=43\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:49:30.540481Z","iopub.execute_input":"2022-04-04T18:49:30.540726Z","iopub.status.idle":"2022-04-04T18:49:30.647729Z","shell.execute_reply.started":"2022-04-04T18:49:30.540693Z","shell.execute_reply":"2022-04-04T18:49:30.647092Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"val_set = train_datagen.flow_from_directory(\n    directory='../input/cotton-disease-dataset/Cotton Disease/val',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=43\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:49:30.648851Z","iopub.execute_input":"2022-04-04T18:49:30.649167Z","iopub.status.idle":"2022-04-04T18:49:30.759696Z","shell.execute_reply.started":"2022-04-04T18:49:30.649131Z","shell.execute_reply":"2022-04-04T18:49:30.759071Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# **VGG 16**","metadata":{}},{"cell_type":"code","source":"model2 = VGG16(input_shape=(224, 224, 3), weights='imagenet', include_top=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:49:30.760860Z","iopub.execute_input":"2022-04-04T18:49:30.761174Z","iopub.status.idle":"2022-04-04T18:49:31.385901Z","shell.execute_reply.started":"2022-04-04T18:49:30.761138Z","shell.execute_reply":"2022-04-04T18:49:31.385171Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"for layer in model2.layers:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:49:31.404269Z","iopub.execute_input":"2022-04-04T18:49:31.404720Z","iopub.status.idle":"2022-04-04T18:49:31.411078Z","shell.execute_reply.started":"2022-04-04T18:49:31.404679Z","shell.execute_reply":"2022-04-04T18:49:31.410411Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"x = Flatten()(model2.output)\n\npred = Dense(4, activation='softmax')(x)\n\nmodel2 = Model(inputs=model2.input, outputs=pred)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:49:31.412469Z","iopub.execute_input":"2022-04-04T18:49:31.413026Z","iopub.status.idle":"2022-04-04T18:49:31.433147Z","shell.execute_reply.started":"2022-04-04T18:49:31.412989Z","shell.execute_reply":"2022-04-04T18:49:31.432518Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:49:31.434104Z","iopub.execute_input":"2022-04-04T18:49:31.434323Z","iopub.status.idle":"2022-04-04T18:49:31.448918Z","shell.execute_reply.started":"2022-04-04T18:49:31.434291Z","shell.execute_reply":"2022-04-04T18:49:31.447815Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model2.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\n\nh = model2.fit(train_set, validation_data=val_set, epochs=10, steps_per_epoch=len(train_set), validation_steps=len(val_set))\n\npreds = model2.predict(test_set)\npreds = np.argmax(preds, axis=1)\nprint(preds)\n\nmodel2.evaluate(test_set)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:49:31.449899Z","iopub.execute_input":"2022-04-04T18:49:31.450516Z","iopub.status.idle":"2022-04-04T18:55:58.253856Z","shell.execute_reply.started":"2022-04-04T18:49:31.450480Z","shell.execute_reply":"2022-04-04T18:55:58.252864Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## **So, VGG16 model gives 92.5% accurate model**","metadata":{}},{"cell_type":"markdown","source":"### Analyzing loss and accuracy with VGG16 model","metadata":{}},{"cell_type":"code","source":"plt.plot(h.history['loss'], label='train_loss')\nplt.plot(h.history['val_loss'], label='val_loss')\nplt.legend()\nplt.title('Training and validation set loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:55:58.257119Z","iopub.execute_input":"2022-04-04T18:55:58.259778Z","iopub.status.idle":"2022-04-04T18:55:58.533136Z","shell.execute_reply.started":"2022-04-04T18:55:58.259739Z","shell.execute_reply":"2022-04-04T18:55:58.532316Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"plt.plot(h.history['accuracy'], label='train_accuracy')\nplt.plot(h.history['val_accuracy'], label='val_accuracy')\nplt.legend()\nplt.title('Training and validation set accuracy')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:55:58.537919Z","iopub.execute_input":"2022-04-04T18:55:58.538576Z","iopub.status.idle":"2022-04-04T18:55:58.789319Z","shell.execute_reply.started":"2022-04-04T18:55:58.538538Z","shell.execute_reply":"2022-04-04T18:55:58.788284Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# **VGG19**","metadata":{}},{"cell_type":"code","source":"model3 = VGG19(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\n\nfor layer in model3.layers:\n    layer.trainable = False\n    \nx = Flatten()(model3.output)\n\npred = Dense(4, activation='softmax')(x)\n\nmodel3 = Model(inputs=model3.input, outputs=pred)\n\nmodel3.summary()\n\nmodel3.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:55:58.793359Z","iopub.execute_input":"2022-04-04T18:55:58.795650Z","iopub.status.idle":"2022-04-04T18:55:59.631723Z","shell.execute_reply.started":"2022-04-04T18:55:58.795607Z","shell.execute_reply":"2022-04-04T18:55:59.630978Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"h = model3.fit(train_set, validation_data=val_set, epochs=10, steps_per_epoch=len(train_set), validation_steps=len(val_set))\n\npreds = model3.predict(test_set)\npreds = np.argmax(preds, axis=1)\nprint(preds)\n\n\nmodel3.evaluate(test_set)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T18:55:59.633025Z","iopub.execute_input":"2022-04-04T18:55:59.634448Z","iopub.status.idle":"2022-04-04T19:02:08.225180Z","shell.execute_reply.started":"2022-04-04T18:55:59.634407Z","shell.execute_reply":"2022-04-04T19:02:08.224503Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"## **VGG19 model 93.3% accuracy**","metadata":{}},{"cell_type":"markdown","source":"### Analyzing loss and accuracy with VGG19 model","metadata":{}},{"cell_type":"code","source":"plt.plot(h.history['loss'], label='train_loss')\nplt.plot(h.history['val_loss'], label='val_loss')\nplt.legend()\nplt.title('Training and validation set loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:02:08.226602Z","iopub.execute_input":"2022-04-04T19:02:08.226848Z","iopub.status.idle":"2022-04-04T19:02:08.416543Z","shell.execute_reply.started":"2022-04-04T19:02:08.226813Z","shell.execute_reply":"2022-04-04T19:02:08.415822Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"plt.plot(h.history['accuracy'], label='train_accuracy')\nplt.plot(h.history['val_accuracy'], label='val_accuracy')\nplt.legend()\nplt.title('Training and validation set Accuracy')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:02:08.417600Z","iopub.execute_input":"2022-04-04T19:02:08.417833Z","iopub.status.idle":"2022-04-04T19:02:08.597030Z","shell.execute_reply.started":"2022-04-04T19:02:08.417798Z","shell.execute_reply":"2022-04-04T19:02:08.596327Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# **Inception Net**","metadata":{}},{"cell_type":"code","source":"from keras.applications.inception_v3 import InceptionV3","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:02:08.598123Z","iopub.execute_input":"2022-04-04T19:02:08.598446Z","iopub.status.idle":"2022-04-04T19:02:08.602829Z","shell.execute_reply.started":"2022-04-04T19:02:08.598408Z","shell.execute_reply":"2022-04-04T19:02:08.601959Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"**Loading the model**","metadata":{}},{"cell_type":"code","source":"model4 = InceptionV3(include_top=False, weights='imagenet', input_shape=(224, 224, 3))","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:02:08.604387Z","iopub.execute_input":"2022-04-04T19:02:08.604654Z","iopub.status.idle":"2022-04-04T19:02:10.807801Z","shell.execute_reply.started":"2022-04-04T19:02:08.604619Z","shell.execute_reply":"2022-04-04T19:02:10.807092Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"for layer in model4.layers:\n    layer.trainable = False\n    \nx = Flatten()(model4.output)\n\npreds = Dense(1000, activation='relu')(x)\npreds = Dense(4, activation='softmax')(preds)\n\nmodel4 = Model(inputs=model4.input, outputs=preds)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:02:10.808977Z","iopub.execute_input":"2022-04-04T19:02:10.809246Z","iopub.status.idle":"2022-04-04T19:02:10.857902Z","shell.execute_reply.started":"2022-04-04T19:02:10.809212Z","shell.execute_reply":"2022-04-04T19:02:10.857277Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"**Plotting the model**","metadata":{}},{"cell_type":"code","source":"tf.config.run_functions_eagerly(True)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:02:15.748713Z","iopub.execute_input":"2022-04-04T19:02:15.749203Z","iopub.status.idle":"2022-04-04T19:02:15.755100Z","shell.execute_reply.started":"2022-04-04T19:02:15.749151Z","shell.execute_reply":"2022-04-04T19:02:15.754221Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"model4.compile(\n    loss=tf.keras.losses.categorical_crossentropy,\n    optimizer='adam',\n    metrics=['accuracy']\n)\n\nr = model4.fit(train_set, epochs=15, validation_data=val_set)\n\npreds = model4.predict(test_set)\npreds = np.argmax(preds, axis=1)\nprint(preds)\n\nmodel4.evaluate(test_set)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:02:15.756514Z","iopub.execute_input":"2022-04-04T19:02:15.756922Z","iopub.status.idle":"2022-04-04T19:12:41.387801Z","shell.execute_reply.started":"2022-04-04T19:02:15.756891Z","shell.execute_reply":"2022-04-04T19:12:41.386938Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"## **90.5% accuracy with Inception model**","metadata":{}},{"cell_type":"markdown","source":"### Analyzing loss and accuracy with Inception model","metadata":{}},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train_loss')\nplt.plot(r.history['val_loss'], label='val_loss')\nplt.title('Loss for train v/s validation set')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:12:41.389082Z","iopub.execute_input":"2022-04-04T19:12:41.389554Z","iopub.status.idle":"2022-04-04T19:12:41.651402Z","shell.execute_reply.started":"2022-04-04T19:12:41.389514Z","shell.execute_reply":"2022-04-04T19:12:41.650717Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['accuracy'], label='train_accuracy')\nplt.plot(r.history['val_accuracy'], label='val_accuracy')\nplt.title('accuracy for train v/s validation set')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:12:41.655012Z","iopub.execute_input":"2022-04-04T19:12:41.656865Z","iopub.status.idle":"2022-04-04T19:12:41.866673Z","shell.execute_reply.started":"2022-04-04T19:12:41.656827Z","shell.execute_reply":"2022-04-04T19:12:41.866076Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"# **Inception ResNet V2 model**","metadata":{}},{"cell_type":"code","source":"from keras.applications.inception_resnet_v2 import inception_resnet_block, InceptionResNetV2","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:12:41.870237Z","iopub.execute_input":"2022-04-04T19:12:41.872070Z","iopub.status.idle":"2022-04-04T19:12:41.877348Z","shell.execute_reply.started":"2022-04-04T19:12:41.872020Z","shell.execute_reply":"2022-04-04T19:12:41.876517Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"**Loading the model**","metadata":{}},{"cell_type":"code","source":"model5 = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:12:41.881522Z","iopub.execute_input":"2022-04-04T19:12:41.883908Z","iopub.status.idle":"2022-04-04T19:12:47.458034Z","shell.execute_reply.started":"2022-04-04T19:12:41.883871Z","shell.execute_reply":"2022-04-04T19:12:47.457302Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"for layer in model5.layers:\n    layer.trainable=False","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:12:47.459366Z","iopub.execute_input":"2022-04-04T19:12:47.459618Z","iopub.status.idle":"2022-04-04T19:12:47.488258Z","shell.execute_reply.started":"2022-04-04T19:12:47.459584Z","shell.execute_reply":"2022-04-04T19:12:47.487651Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"**Adding Dense layers**","metadata":{}},{"cell_type":"code","source":"model5.compile(\n    loss=tf.keras.losses.categorical_crossentropy,\n    optimizer='adam',\n    metrics=['accuracy']\n)\n\nr = model5.fit(train_set, epochs=15, validation_data=val_set)\n\npreds = model5.predict(test_set)\npreds = np.argmax(preds, axis=1)\nprint(preds)\n\n\nmodel5.evaluate(test_set)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:12:48.047514Z","iopub.execute_input":"2022-04-04T19:12:48.047754Z","iopub.status.idle":"2022-04-04T19:26:01.687234Z","shell.execute_reply.started":"2022-04-04T19:12:48.047720Z","shell.execute_reply":"2022-04-04T19:26:01.686370Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"## **93.3% accuracy with Inception-ResnetV2 model**","metadata":{}},{"cell_type":"markdown","source":"### Analyzing loss and accuracy with Inception-ResNetV2 model","metadata":{}},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train_loss')\nplt.plot(r.history['val_loss'], label='val_loss')\nplt.title('Loss for train v/s validation set')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:26:01.688481Z","iopub.execute_input":"2022-04-04T19:26:01.688822Z","iopub.status.idle":"2022-04-04T19:26:01.882496Z","shell.execute_reply.started":"2022-04-04T19:26:01.688784Z","shell.execute_reply":"2022-04-04T19:26:01.881845Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['accuracy'], label='train_accuracy')\nplt.plot(r.history['val_accuracy'], label='val_accuracy')\nplt.title('accuracy for train v/s validation set')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:26:01.883560Z","iopub.execute_input":"2022-04-04T19:26:01.883913Z","iopub.status.idle":"2022-04-04T19:26:02.150490Z","shell.execute_reply.started":"2022-04-04T19:26:01.883878Z","shell.execute_reply":"2022-04-04T19:26:02.148117Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"# Combining Results","metadata":{}},{"cell_type":"code","source":"models = {\n    'VGG16': model2.evaluate(test_set),\n    'VGG19': model3.evaluate(test_set),\n    'Inception': model4.evaluate(test_set),\n    'Inception-ResNet-V2': model5.evaluate(test_set)\n}\n\nmodels_outcome = pd.DataFrame(models).T\nmodels_outcome.columns=['loss', 'accuracy']\nmodels_outcome","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:26:02.154585Z","iopub.execute_input":"2022-04-04T19:26:02.156935Z","iopub.status.idle":"2022-04-04T19:26:27.510100Z","shell.execute_reply.started":"2022-04-04T19:26:02.156893Z","shell.execute_reply":"2022-04-04T19:26:27.509433Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}